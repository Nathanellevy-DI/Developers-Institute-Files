{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone Serverless Reranking Daily Challenge\n",
    "\n",
    "## Part 1: Load Documents & Execute Reranking Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Pinecone libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pinecone-client==6.0.1 pinecone-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Authenticate with Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.environ.get(\"PINECONE_API_KEY\"):\n",
    "    from pinecone_notebooks.colab import Authenticate\n",
    "    Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Instantiate the Pinecone client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define your query & documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me about Apple's products\"\n",
    "documents = [\n",
    "    \"Apple is a nutrient-rich fruit that comes in various colors like red, green, and yellow.\",\n",
    "    \"Apple Inc. designs and manufactures consumer electronics like the iPhone, iPad, and Mac.\",\n",
    "    \"Apples are high in fiber and vitamin C, making them a healthy snack choice.\",\n",
    "    \"Apple recently announced its new Vision Pro headset for spatial computing.\",\n",
    "    \"The Granny Smith apple is known for its tart flavor and crisp texture.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Call the reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import RerankModel\n",
    "\n",
    "reranked = pc.inference.rerank(\n",
    "    model=\"bge-reranker-v2-m3\",\n",
    "    query=query,\n",
    "    documents=[{\"id\": str(i), \"text\": doc} for i, doc in enumerate(documents)],\n",
    "    top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Inspect reranked results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reranked_results(query, matches):\n",
    "    print(f\"Query: {query}\")\n",
    "    for i, m in enumerate(matches):\n",
    "        print(f\"Rank: {i+1}\")\n",
    "        print(f\"Score: {m.score}\")\n",
    "        print(f\"Text: {m.document.text}\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "show_reranked_results(query, reranked.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Setup a Serverless Index for Medical Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install data & model libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas torch transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import modules & define environment settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "cloud = os.getenv('PINECONE_CLOUD', 'aws')\n",
    "region = os.getenv('PINECONE_REGION', 'us-east-1')\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "\n",
    "index_name = 'medical-notes-index'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create or recreate the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pc.has_index(name=index_name):\n",
    "    pc.delete_index(name=index_name)\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,\n",
    "    metric='cosine',\n",
    "    spec=spec\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Load the Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download & read JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tempfile\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "    file_path = os.path.join(tmpdirname, \"sample_notes_data.jsonl\")\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/pinecone-io/examples/refs/heads/master/docs/data/sample_notes_data.jsonl\"\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    df = pd.read_json(file_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preview the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Upsert Data into the Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Instantiate index client & upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(name=index_name)\n",
    "index.upsert_from_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wait for availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_fresh(index):\n",
    "    stats = index.describe_index_stats()\n",
    "    vector_count = stats.total_vector_count\n",
    "    print(f\"Vector count: \", vector_count)\n",
    "    return vector_count > 0\n",
    "\n",
    "while not is_fresh(index):\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"Index ready!\")\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Query & Embedding Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define your embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(input_question):\n",
    "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    encoded_input = tokenizer(input_question, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    embedding = model_output.last_hidden_state[0].mean(dim=0)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Run a semantic search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the signs of a concussion?\"\n",
    "query = get_embedding(question).tolist()\n",
    "\n",
    "results = index.query(vector=[query], top_k=5, include_metadata=True)\n",
    "\n",
    "sorted_matches = sorted(results['matches'], key=lambda x: x['score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Display & Rerank Clinical Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Display initial search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(question, matches):\n",
    "    print(f'Question: \\'{question}\\'')\n",
    "    print('\\nResults:')\n",
    "    for i, match in enumerate(matches):\n",
    "        print(f'{str(i+1).rjust(4)}. ID: {match[\"id\"]}')\n",
    "        print(f' Score: {match[\"score\"]}')\n",
    "        print(f' Metadata: {match[\"metadata\"]}')\n",
    "        print('')\n",
    "\n",
    "show_results(question, sorted_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare documents for reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_documents = [\n",
    "    {\n",
    "        'id': match['id'],\n",
    "        'reranking_field': '; '.join([f\"{key}: {value}\" for key, value in match['metadata'].items()])\n",
    "    }\n",
    "    for match in results['matches']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Execute serverless reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_query = \"What are the immediate symptoms of a head injury like a concussion?\"\n",
    "\n",
    "reranked_results = pc.inference.rerank(\n",
    "    model=\"bge-reranker-v2-m3\",\n",
    "    query=refined_query,\n",
    "    documents=transformed_documents,\n",
    "    rank_fields=[\"reranking_field\"],\n",
    "    top_n=3,\n",
    "    return_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Show reranked results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_reranked_results_final(question, matches):\n",
    "    print(f'Question: \\'{question}\\'')\n",
    "    print('\\nReranked Results:')\n",
    "    for i, match in enumerate(matches):\n",
    "        print(f'{str(i+1).rjust(4)}. ID: {match.document.id}')\n",
    "        print(f' Score: {match.score}')\n",
    "        print(f' Reranking Field: {match.document.reranking_field}')\n",
    "        print('')\n",
    "        \n",
    "show_reranked_results_final(refined_query, reranked_results.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index(name=index_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
